{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9de4f3ac",
   "metadata": {},
   "source": [
    "# WEB SCRAPING – ASSIGNMENT 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa8107fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\sandeep\\anaconda3\\lib\\site-packages (4.10.0)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\users\\sandeep\\anaconda3\\lib\\site-packages (from selenium) (1.26.16)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\sandeep\\anaconda3\\lib\\site-packages (from selenium) (0.22.2)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\sandeep\\anaconda3\\lib\\site-packages (from selenium) (0.10.3)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\sandeep\\anaconda3\\lib\\site-packages (from selenium) (2023.5.7)\n",
      "Requirement already satisfied: attrs>=20.1.0 in c:\\users\\sandeep\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (22.1.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\sandeep\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\sandeep\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Requirement already satisfied: outcome in c:\\users\\sandeep\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\sandeep\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\sandeep\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\sandeep\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.1.2)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\sandeep\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\sandeep\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\sandeep\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\sandeep\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Requirement already satisfied: webdriver-manager in c:\\users\\sandeep\\anaconda3\\lib\\site-packages (3.8.6)\n",
      "Requirement already satisfied: requests in c:\\users\\sandeep\\anaconda3\\lib\\site-packages (from webdriver-manager) (2.29.0)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\sandeep\\anaconda3\\lib\\site-packages (from webdriver-manager) (1.0.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\sandeep\\anaconda3\\lib\\site-packages (from webdriver-manager) (4.65.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\sandeep\\anaconda3\\lib\\site-packages (from webdriver-manager) (23.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sandeep\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sandeep\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\sandeep\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sandeep\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (2023.5.7)\n",
      "Requirement already satisfied: colorama in c:\\users\\sandeep\\anaconda3\\lib\\site-packages (from tqdm->webdriver-manager) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "! pip install selenium\n",
    "! pip install webdriver-manager"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08eee25f",
   "metadata": {},
   "source": [
    "# 1. Scrape the details of most viewed videos on YouTube from Wikipedia. Url = \n",
    "https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos You need to find following details: \n",
    "A) Rank \n",
    "B) Name \n",
    "C) Artist \n",
    "D) Upload date \n",
    "E) Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6fc3c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "import re\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3a6fa15",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = selenium.webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0269b77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d42f7d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the empty lists to store the scraped data\n",
    "Rank=[]\n",
    "Name=[]\n",
    "Artist=[]\n",
    "Views=[]\n",
    "Upload_Date=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bf36b8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#As we need only the first 30 details, we will iterate only for first 30 data\n",
    "#Scrapping the details of the Rank of the video\n",
    "rank=driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter']/tbody/tr/td[1]\")\n",
    "for i in rank[:30]:\n",
    "    Rank.append(i.text)\n",
    "\n",
    "#Scrapping the details of the video name\n",
    "video=driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter']/tbody/tr/td[2]\")\n",
    "for i in video[:30]:\n",
    "    Name.append(i.text)\n",
    "    \n",
    "#Scrapping the details of the Artist name\n",
    "artist=driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter']/tbody/tr/td[3]\")\n",
    "for i in artist[:30]:\n",
    "    Artist.append(i.text)\n",
    "    \n",
    "#Scrapping the details of the views information\n",
    "views=driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter']/tbody/tr/td[4]\")\n",
    "for i in views[:30]:\n",
    "    Views.append(i.text)\n",
    "    \n",
    "#Scrapping the details of the upload date\n",
    "date=driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter']/tbody/tr/td[5]\")\n",
    "for i in date[:30]:\n",
    "    Upload_Date.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b62de07a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 30 30 30 30\n"
     ]
    }
   ],
   "source": [
    "#Checking the length of the data scraped\n",
    "print(len(Rank),len(Name),len(Artist),len(Views),len(Upload_Date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b797e625",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Video Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Views(Billions)</th>\n",
       "      <th>Upload Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>\"Baby Shark Dance\"[6]</td>\n",
       "      <td>Pinkfong Baby Shark - children's songs</td>\n",
       "      <td>13.18</td>\n",
       "      <td>June 17, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>\"Despacito\"[9]</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>8.23</td>\n",
       "      <td>January 12, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>\"Johny Johny Yes Papa\"[16]</td>\n",
       "      <td>LooLoo Kids - nursery rhymes</td>\n",
       "      <td>6.76</td>\n",
       "      <td>October 8, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>\"Bath Song\"[17]</td>\n",
       "      <td>Cocomelon - nursery rhymes</td>\n",
       "      <td>6.33</td>\n",
       "      <td>May 2, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>\"Shape of You\"[18]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>6.05</td>\n",
       "      <td>January 30, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.</td>\n",
       "      <td>\"See You Again\"[21]</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>5.98</td>\n",
       "      <td>April 6, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.</td>\n",
       "      <td>\"Wheels on the Bus\"[26]</td>\n",
       "      <td>Cocomelon - nursery rhymes</td>\n",
       "      <td>5.46</td>\n",
       "      <td>May 24, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.</td>\n",
       "      <td>\"Phonics Song with Two Words\"[27]</td>\n",
       "      <td>ChuChu TV - children's songs</td>\n",
       "      <td>5.42</td>\n",
       "      <td>March 6, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.</td>\n",
       "      <td>\"Uptown Funk\"[28]</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>5.00</td>\n",
       "      <td>November 19, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.</td>\n",
       "      <td>\"Learning Colors – Colorful Eggs on a Farm\"[29]</td>\n",
       "      <td>Miroshka TV - children's songs</td>\n",
       "      <td>4.94</td>\n",
       "      <td>February 27, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.</td>\n",
       "      <td>\"Gangnam Style\"[30]</td>\n",
       "      <td>Psy</td>\n",
       "      <td>4.86</td>\n",
       "      <td>July 15, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.</td>\n",
       "      <td>\"Masha and the Bear – Recipe for Disaster\"[35]</td>\n",
       "      <td>Get Movies - children's songs</td>\n",
       "      <td>4.55</td>\n",
       "      <td>January 31, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.</td>\n",
       "      <td>\"Dame Tu Cosita\"[36]</td>\n",
       "      <td>El Chombo</td>\n",
       "      <td>4.41</td>\n",
       "      <td>April 5, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.</td>\n",
       "      <td>\"Axel F\"[37]</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>4.00</td>\n",
       "      <td>June 16, 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.</td>\n",
       "      <td>\"Sugar\"[38]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>3.91</td>\n",
       "      <td>January 14, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.</td>\n",
       "      <td>\"Roar\"[39]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>3.84</td>\n",
       "      <td>September 5, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.</td>\n",
       "      <td>\"Counting Stars\"[40]</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>3.84</td>\n",
       "      <td>May 31, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.</td>\n",
       "      <td>\"Baa Baa Black Sheep\"[41]</td>\n",
       "      <td>Cocomelon - nursery rhymes</td>\n",
       "      <td>3.73</td>\n",
       "      <td>June 25, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.</td>\n",
       "      <td>\"Sorry\"[42]</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>3.69</td>\n",
       "      <td>October 22, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.</td>\n",
       "      <td>\"Waka Waka (This Time for Africa)\"[43]</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>3.68</td>\n",
       "      <td>June 4, 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.</td>\n",
       "      <td>\"Thinking Out Loud\"[44]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>3.63</td>\n",
       "      <td>October 7, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.</td>\n",
       "      <td>\"Lakdi Ki Kathi\"[45]</td>\n",
       "      <td>Jingle Toons</td>\n",
       "      <td>3.63</td>\n",
       "      <td>June 14, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.</td>\n",
       "      <td>\"Dark Horse\"[46]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>3.56</td>\n",
       "      <td>February 20, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.</td>\n",
       "      <td>\"Perfect\"[47]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>3.51</td>\n",
       "      <td>November 9, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25.</td>\n",
       "      <td>\"Faded\"[48]</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>3.49</td>\n",
       "      <td>December 3, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26.</td>\n",
       "      <td>\"Let Her Go\"[49]</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>3.48</td>\n",
       "      <td>July 25, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.</td>\n",
       "      <td>\"Humpty the train on a fruits ride\"[50]</td>\n",
       "      <td>Kiddiestv Hindi - children's songs</td>\n",
       "      <td>3.51</td>\n",
       "      <td>January 26, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.</td>\n",
       "      <td>\"Girls Like You\"[51]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>3.45</td>\n",
       "      <td>May 31, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29.</td>\n",
       "      <td>\"Bailando\"[52]</td>\n",
       "      <td>Enrique Iglesias</td>\n",
       "      <td>3.43</td>\n",
       "      <td>April 11, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.</td>\n",
       "      <td>\"Lean On\"[53]</td>\n",
       "      <td>Major Lazer</td>\n",
       "      <td>3.43</td>\n",
       "      <td>March 22, 2015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                                       Video Name  \\\n",
       "0    1.                            \"Baby Shark Dance\"[6]   \n",
       "1    2.                                   \"Despacito\"[9]   \n",
       "2    3.                       \"Johny Johny Yes Papa\"[16]   \n",
       "3    4.                                  \"Bath Song\"[17]   \n",
       "4    5.                               \"Shape of You\"[18]   \n",
       "5    6.                              \"See You Again\"[21]   \n",
       "6    7.                          \"Wheels on the Bus\"[26]   \n",
       "7    8.                \"Phonics Song with Two Words\"[27]   \n",
       "8    9.                                \"Uptown Funk\"[28]   \n",
       "9   10.  \"Learning Colors – Colorful Eggs on a Farm\"[29]   \n",
       "10  11.                              \"Gangnam Style\"[30]   \n",
       "11  12.   \"Masha and the Bear – Recipe for Disaster\"[35]   \n",
       "12  13.                             \"Dame Tu Cosita\"[36]   \n",
       "13  14.                                     \"Axel F\"[37]   \n",
       "14  15.                                      \"Sugar\"[38]   \n",
       "15  16.                                       \"Roar\"[39]   \n",
       "16  17.                             \"Counting Stars\"[40]   \n",
       "17  18.                        \"Baa Baa Black Sheep\"[41]   \n",
       "18  19.                                      \"Sorry\"[42]   \n",
       "19  20.           \"Waka Waka (This Time for Africa)\"[43]   \n",
       "20  21.                          \"Thinking Out Loud\"[44]   \n",
       "21  22.                             \"Lakdi Ki Kathi\"[45]   \n",
       "22  23.                                 \"Dark Horse\"[46]   \n",
       "23  24.                                    \"Perfect\"[47]   \n",
       "24  25.                                      \"Faded\"[48]   \n",
       "25  26.                                 \"Let Her Go\"[49]   \n",
       "26  27.          \"Humpty the train on a fruits ride\"[50]   \n",
       "27  28.                             \"Girls Like You\"[51]   \n",
       "28  29.                                   \"Bailando\"[52]   \n",
       "29  30.                                    \"Lean On\"[53]   \n",
       "\n",
       "                                    Artist Views(Billions)        Upload Date  \n",
       "0   Pinkfong Baby Shark - children's songs           13.18      June 17, 2016  \n",
       "1                               Luis Fonsi            8.23   January 12, 2017  \n",
       "2             LooLoo Kids - nursery rhymes            6.76    October 8, 2016  \n",
       "3               Cocomelon - nursery rhymes            6.33        May 2, 2018  \n",
       "4                               Ed Sheeran            6.05   January 30, 2017  \n",
       "5                              Wiz Khalifa            5.98      April 6, 2015  \n",
       "6               Cocomelon - nursery rhymes            5.46       May 24, 2018  \n",
       "7             ChuChu TV - children's songs            5.42      March 6, 2014  \n",
       "8                              Mark Ronson            5.00  November 19, 2014  \n",
       "9           Miroshka TV - children's songs            4.94  February 27, 2018  \n",
       "10                                     Psy            4.86      July 15, 2012  \n",
       "11           Get Movies - children's songs            4.55   January 31, 2012  \n",
       "12                               El Chombo            4.41      April 5, 2018  \n",
       "13                              Crazy Frog            4.00      June 16, 2009  \n",
       "14                                Maroon 5            3.91   January 14, 2015  \n",
       "15                              Katy Perry            3.84  September 5, 2013  \n",
       "16                             OneRepublic            3.84       May 31, 2013  \n",
       "17              Cocomelon - nursery rhymes            3.73      June 25, 2018  \n",
       "18                           Justin Bieber            3.69   October 22, 2015  \n",
       "19                                 Shakira            3.68       June 4, 2010  \n",
       "20                              Ed Sheeran            3.63    October 7, 2014  \n",
       "21                            Jingle Toons            3.63      June 14, 2018  \n",
       "22                              Katy Perry            3.56  February 20, 2014  \n",
       "23                              Ed Sheeran            3.51   November 9, 2017  \n",
       "24                             Alan Walker            3.49   December 3, 2015  \n",
       "25                               Passenger            3.48      July 25, 2012  \n",
       "26      Kiddiestv Hindi - children's songs            3.51   January 26, 2018  \n",
       "27                                Maroon 5            3.45       May 31, 2018  \n",
       "28                        Enrique Iglesias            3.43     April 11, 2014  \n",
       "29                             Major Lazer            3.43     March 22, 2015  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating a dataframe for storing the scraped data\n",
    "Yt_data=pd.DataFrame({})\n",
    "Yt_data['Rank']=Rank\n",
    "Yt_data['Video Name']=Name\n",
    "Yt_data['Artist']=Artist\n",
    "Yt_data['Views(Billions)']=Views\n",
    "Yt_data['Upload Date']=Upload_Date\n",
    "Yt_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dc605575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Baby Shark Dance\"</td>\n",
       "      <td>6]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Despacito\"</td>\n",
       "      <td>9]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Johny Johny Yes Papa\"</td>\n",
       "      <td>16]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Bath Song\"</td>\n",
       "      <td>17]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Shape of You\"</td>\n",
       "      <td>18]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"See You Again\"</td>\n",
       "      <td>21]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\"Wheels on the Bus\"</td>\n",
       "      <td>26]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\"Phonics Song with Two Words\"</td>\n",
       "      <td>27]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\"Uptown Funk\"</td>\n",
       "      <td>28]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\"Learning Colors – Colorful Eggs on a Farm\"</td>\n",
       "      <td>29]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>\"Gangnam Style\"</td>\n",
       "      <td>30]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>\"Masha and the Bear – Recipe for Disaster\"</td>\n",
       "      <td>35]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>\"Dame Tu Cosita\"</td>\n",
       "      <td>36]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>\"Axel F\"</td>\n",
       "      <td>37]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>\"Sugar\"</td>\n",
       "      <td>38]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>\"Roar\"</td>\n",
       "      <td>39]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>\"Counting Stars\"</td>\n",
       "      <td>40]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>\"Baa Baa Black Sheep\"</td>\n",
       "      <td>41]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>\"Sorry\"</td>\n",
       "      <td>42]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>\"Waka Waka (This Time for Africa)\"</td>\n",
       "      <td>43]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>\"Thinking Out Loud\"</td>\n",
       "      <td>44]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>\"Lakdi Ki Kathi\"</td>\n",
       "      <td>45]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>\"Dark Horse\"</td>\n",
       "      <td>46]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>\"Perfect\"</td>\n",
       "      <td>47]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>\"Faded\"</td>\n",
       "      <td>48]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>\"Let Her Go\"</td>\n",
       "      <td>49]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>\"Humpty the train on a fruits ride\"</td>\n",
       "      <td>50]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>\"Girls Like You\"</td>\n",
       "      <td>51]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>\"Bailando\"</td>\n",
       "      <td>52]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>\"Lean On\"</td>\n",
       "      <td>53]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              0    1\n",
       "0                            \"Baby Shark Dance\"   6]\n",
       "1                                   \"Despacito\"   9]\n",
       "2                        \"Johny Johny Yes Papa\"  16]\n",
       "3                                   \"Bath Song\"  17]\n",
       "4                                \"Shape of You\"  18]\n",
       "5                               \"See You Again\"  21]\n",
       "6                           \"Wheels on the Bus\"  26]\n",
       "7                 \"Phonics Song with Two Words\"  27]\n",
       "8                                 \"Uptown Funk\"  28]\n",
       "9   \"Learning Colors – Colorful Eggs on a Farm\"  29]\n",
       "10                              \"Gangnam Style\"  30]\n",
       "11   \"Masha and the Bear – Recipe for Disaster\"  35]\n",
       "12                             \"Dame Tu Cosita\"  36]\n",
       "13                                     \"Axel F\"  37]\n",
       "14                                      \"Sugar\"  38]\n",
       "15                                       \"Roar\"  39]\n",
       "16                             \"Counting Stars\"  40]\n",
       "17                        \"Baa Baa Black Sheep\"  41]\n",
       "18                                      \"Sorry\"  42]\n",
       "19           \"Waka Waka (This Time for Africa)\"  43]\n",
       "20                          \"Thinking Out Loud\"  44]\n",
       "21                             \"Lakdi Ki Kathi\"  45]\n",
       "22                                 \"Dark Horse\"  46]\n",
       "23                                    \"Perfect\"  47]\n",
       "24                                      \"Faded\"  48]\n",
       "25                                 \"Let Her Go\"  49]\n",
       "26          \"Humpty the train on a fruits ride\"  50]\n",
       "27                             \"Girls Like You\"  51]\n",
       "28                                   \"Bailando\"  52]\n",
       "29                                    \"Lean On\"  53]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Removing the stray numbers from videoname\n",
    "new=Yt_data[\"Video Name\"].str.split(\"[\", n = 1, expand = True) \n",
    "new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c8b7f603",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping the column with stray numbers\n",
    "Yt_data.drop(columns=['Video Name'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b3ed1ef9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Video Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Views(Billions)</th>\n",
       "      <th>Upload Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>\"Baby Shark Dance\"</td>\n",
       "      <td>Pinkfong Baby Shark - children's songs</td>\n",
       "      <td>13.18</td>\n",
       "      <td>June 17, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>\"Despacito\"</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>8.23</td>\n",
       "      <td>January 12, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>\"Johny Johny Yes Papa\"</td>\n",
       "      <td>LooLoo Kids - nursery rhymes</td>\n",
       "      <td>6.76</td>\n",
       "      <td>October 8, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>\"Bath Song\"</td>\n",
       "      <td>Cocomelon - nursery rhymes</td>\n",
       "      <td>6.33</td>\n",
       "      <td>May 2, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>\"Shape of You\"</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>6.05</td>\n",
       "      <td>January 30, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.</td>\n",
       "      <td>\"See You Again\"</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>5.98</td>\n",
       "      <td>April 6, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.</td>\n",
       "      <td>\"Wheels on the Bus\"</td>\n",
       "      <td>Cocomelon - nursery rhymes</td>\n",
       "      <td>5.46</td>\n",
       "      <td>May 24, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.</td>\n",
       "      <td>\"Phonics Song with Two Words\"</td>\n",
       "      <td>ChuChu TV - children's songs</td>\n",
       "      <td>5.42</td>\n",
       "      <td>March 6, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.</td>\n",
       "      <td>\"Uptown Funk\"</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>5.00</td>\n",
       "      <td>November 19, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.</td>\n",
       "      <td>\"Learning Colors – Colorful Eggs on a Farm\"</td>\n",
       "      <td>Miroshka TV - children's songs</td>\n",
       "      <td>4.94</td>\n",
       "      <td>February 27, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.</td>\n",
       "      <td>\"Gangnam Style\"</td>\n",
       "      <td>Psy</td>\n",
       "      <td>4.86</td>\n",
       "      <td>July 15, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.</td>\n",
       "      <td>\"Masha and the Bear – Recipe for Disaster\"</td>\n",
       "      <td>Get Movies - children's songs</td>\n",
       "      <td>4.55</td>\n",
       "      <td>January 31, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.</td>\n",
       "      <td>\"Dame Tu Cosita\"</td>\n",
       "      <td>El Chombo</td>\n",
       "      <td>4.41</td>\n",
       "      <td>April 5, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.</td>\n",
       "      <td>\"Axel F\"</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>4.00</td>\n",
       "      <td>June 16, 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.</td>\n",
       "      <td>\"Sugar\"</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>3.91</td>\n",
       "      <td>January 14, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.</td>\n",
       "      <td>\"Roar\"</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>3.84</td>\n",
       "      <td>September 5, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.</td>\n",
       "      <td>\"Counting Stars\"</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>3.84</td>\n",
       "      <td>May 31, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.</td>\n",
       "      <td>\"Baa Baa Black Sheep\"</td>\n",
       "      <td>Cocomelon - nursery rhymes</td>\n",
       "      <td>3.73</td>\n",
       "      <td>June 25, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.</td>\n",
       "      <td>\"Sorry\"</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>3.69</td>\n",
       "      <td>October 22, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.</td>\n",
       "      <td>\"Waka Waka (This Time for Africa)\"</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>3.68</td>\n",
       "      <td>June 4, 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.</td>\n",
       "      <td>\"Thinking Out Loud\"</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>3.63</td>\n",
       "      <td>October 7, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.</td>\n",
       "      <td>\"Lakdi Ki Kathi\"</td>\n",
       "      <td>Jingle Toons</td>\n",
       "      <td>3.63</td>\n",
       "      <td>June 14, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.</td>\n",
       "      <td>\"Dark Horse\"</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>3.56</td>\n",
       "      <td>February 20, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.</td>\n",
       "      <td>\"Perfect\"</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>3.51</td>\n",
       "      <td>November 9, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25.</td>\n",
       "      <td>\"Faded\"</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>3.49</td>\n",
       "      <td>December 3, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26.</td>\n",
       "      <td>\"Let Her Go\"</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>3.48</td>\n",
       "      <td>July 25, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.</td>\n",
       "      <td>\"Humpty the train on a fruits ride\"</td>\n",
       "      <td>Kiddiestv Hindi - children's songs</td>\n",
       "      <td>3.51</td>\n",
       "      <td>January 26, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.</td>\n",
       "      <td>\"Girls Like You\"</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>3.45</td>\n",
       "      <td>May 31, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29.</td>\n",
       "      <td>\"Bailando\"</td>\n",
       "      <td>Enrique Iglesias</td>\n",
       "      <td>3.43</td>\n",
       "      <td>April 11, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.</td>\n",
       "      <td>\"Lean On\"</td>\n",
       "      <td>Major Lazer</td>\n",
       "      <td>3.43</td>\n",
       "      <td>March 22, 2015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                                   Video Name  \\\n",
       "0    1.                           \"Baby Shark Dance\"   \n",
       "1    2.                                  \"Despacito\"   \n",
       "2    3.                       \"Johny Johny Yes Papa\"   \n",
       "3    4.                                  \"Bath Song\"   \n",
       "4    5.                               \"Shape of You\"   \n",
       "5    6.                              \"See You Again\"   \n",
       "6    7.                          \"Wheels on the Bus\"   \n",
       "7    8.                \"Phonics Song with Two Words\"   \n",
       "8    9.                                \"Uptown Funk\"   \n",
       "9   10.  \"Learning Colors – Colorful Eggs on a Farm\"   \n",
       "10  11.                              \"Gangnam Style\"   \n",
       "11  12.   \"Masha and the Bear – Recipe for Disaster\"   \n",
       "12  13.                             \"Dame Tu Cosita\"   \n",
       "13  14.                                     \"Axel F\"   \n",
       "14  15.                                      \"Sugar\"   \n",
       "15  16.                                       \"Roar\"   \n",
       "16  17.                             \"Counting Stars\"   \n",
       "17  18.                        \"Baa Baa Black Sheep\"   \n",
       "18  19.                                      \"Sorry\"   \n",
       "19  20.           \"Waka Waka (This Time for Africa)\"   \n",
       "20  21.                          \"Thinking Out Loud\"   \n",
       "21  22.                             \"Lakdi Ki Kathi\"   \n",
       "22  23.                                 \"Dark Horse\"   \n",
       "23  24.                                    \"Perfect\"   \n",
       "24  25.                                      \"Faded\"   \n",
       "25  26.                                 \"Let Her Go\"   \n",
       "26  27.          \"Humpty the train on a fruits ride\"   \n",
       "27  28.                             \"Girls Like You\"   \n",
       "28  29.                                   \"Bailando\"   \n",
       "29  30.                                    \"Lean On\"   \n",
       "\n",
       "                                    Artist Views(Billions)        Upload Date  \n",
       "0   Pinkfong Baby Shark - children's songs           13.18      June 17, 2016  \n",
       "1                               Luis Fonsi            8.23   January 12, 2017  \n",
       "2             LooLoo Kids - nursery rhymes            6.76    October 8, 2016  \n",
       "3               Cocomelon - nursery rhymes            6.33        May 2, 2018  \n",
       "4                               Ed Sheeran            6.05   January 30, 2017  \n",
       "5                              Wiz Khalifa            5.98      April 6, 2015  \n",
       "6               Cocomelon - nursery rhymes            5.46       May 24, 2018  \n",
       "7             ChuChu TV - children's songs            5.42      March 6, 2014  \n",
       "8                              Mark Ronson            5.00  November 19, 2014  \n",
       "9           Miroshka TV - children's songs            4.94  February 27, 2018  \n",
       "10                                     Psy            4.86      July 15, 2012  \n",
       "11           Get Movies - children's songs            4.55   January 31, 2012  \n",
       "12                               El Chombo            4.41      April 5, 2018  \n",
       "13                              Crazy Frog            4.00      June 16, 2009  \n",
       "14                                Maroon 5            3.91   January 14, 2015  \n",
       "15                              Katy Perry            3.84  September 5, 2013  \n",
       "16                             OneRepublic            3.84       May 31, 2013  \n",
       "17              Cocomelon - nursery rhymes            3.73      June 25, 2018  \n",
       "18                           Justin Bieber            3.69   October 22, 2015  \n",
       "19                                 Shakira            3.68       June 4, 2010  \n",
       "20                              Ed Sheeran            3.63    October 7, 2014  \n",
       "21                            Jingle Toons            3.63      June 14, 2018  \n",
       "22                              Katy Perry            3.56  February 20, 2014  \n",
       "23                              Ed Sheeran            3.51   November 9, 2017  \n",
       "24                             Alan Walker            3.49   December 3, 2015  \n",
       "25                               Passenger            3.48      July 25, 2012  \n",
       "26      Kiddiestv Hindi - children's songs            3.51   January 26, 2018  \n",
       "27                                Maroon 5            3.45       May 31, 2018  \n",
       "28                        Enrique Iglesias            3.43     April 11, 2014  \n",
       "29                             Major Lazer            3.43     March 22, 2015  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Inserting the name column\n",
    "Yt_data.insert(1,\"Video Name\",new[0])\n",
    "\n",
    "#Checking the data after removing the stray numbers\n",
    "Yt_data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1d90c949",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method WebDriver.close of <selenium.webdriver.chrome.webdriver.WebDriver (session=\"36c1be57d231b24c357e3c9d17a63b11\")>>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Closing the driver\n",
    "driver.close"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbb8840",
   "metadata": {},
   "source": [
    "2 . Scrape the details team India’s international fixtures from bcci.tv. \n",
    "Url = https://www.bcci.tv/.\n",
    "You need to find following details: \n",
    "A) Match title (I.e. 1 ODI) \n",
    "B) Series \n",
    "C) Place \n",
    "D) Date \n",
    "E) Time \n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "807e8bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = selenium.webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "9b9b52f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.bcci.tv/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "c61c7de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking on menu\n",
    "button= driver.find_element(By.XPATH,'//span[@class = \"menu-icon__line menu-icon__line-right\"]').get_attribute('href')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "7e2c141c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting International\n",
    "International= driver.find_element(By.XPATH,'//a[@class = \"nav-link \"]').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "1e87f000",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking on dropdown\n",
    "Select= driver.find_element(By.XPATH,'/html/body/div[2]/div[2]/div/div/div/div[2]/div[2]/div/div[3]/div/div[1]').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "ea202866",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting ODI\n",
    "OdI= driver.find_element(By.XPATH,'/html/body/div[2]/div[2]/div/div/div/div[2]/div[2]/div/div[3]/div/div[2]/div[3]').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "56753338",
   "metadata": {},
   "outputs": [],
   "source": [
    "Match_title= []\n",
    "Series= []\n",
    "Place= []\n",
    "Date= []\n",
    "Time= []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "adc43cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping Match Title\n",
    "try:\n",
    "    Match_title_tag= driver.find_elements(By.XPATH,\"//div[@class='match-card-top']\")\n",
    "    for i in Match_title_tag:\n",
    "        Match_title.append(i.text)\n",
    "except NoSuchElementException as e:\n",
    "    Match_title.append(\"--\")\n",
    "\n",
    "#scraping Series\n",
    "try:\n",
    "    Series_tag= driver.find_elements(By.XPATH,\"//span[@class='matchOrderText ng-binding ng-scope']\")\n",
    "    for i in Series_tag:\n",
    "        Series.append(i.text.split(\"-\"))\n",
    "except NoSuchElementException as e:\n",
    "    Series.append(\"--\")\n",
    "    \n",
    "#scraping Place\n",
    "try:\n",
    "    Place_tag= driver.find_elements(By.XPATH,\"//div[@class='match-dates ng-binding']\")\n",
    "    for i in Place_tag:\n",
    "        Place.append(i.text.split(\"-\"))\n",
    "except NoSuchElementException as e:\n",
    "    Place.append(\"--\") \n",
    "\n",
    "#scraping Date\n",
    "try:\n",
    "    Date_tag= driver.find_elements(By.XPATH,\"//div[@class='match-dates ng-binding']\")\n",
    "    for i in Date_tag:\n",
    "        Date.append(i.text)\n",
    "except NoSuchElementException as e:\n",
    "    Date.append(\"--\")\n",
    "\n",
    "#scraping Time   \n",
    "try:\n",
    "    Time_tag= driver.find_elements(By.XPATH,\"//div[@class='match-time no-margin ng-binding']\")\n",
    "    for i in Time_tag:\n",
    "        Time.append(i.text)\n",
    "except NoSuchElementException as e:\n",
    "    Time.append(\"--\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "89a756b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 8 8 8 8\n"
     ]
    }
   ],
   "source": [
    "#printing length\n",
    "print(len(Match_title),len(Series),len(Place),len(Date),len(Time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "b96a9d36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Match_title</th>\n",
       "      <th>Series</th>\n",
       "      <th>Place</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ASIA CUP 2023\\n2 SEP 2023\\n10:00 AM IST</td>\n",
       "      <td>[1st ODI , ]</td>\n",
       "      <td>[2 SEP 2023]</td>\n",
       "      <td>2 SEP 2023</td>\n",
       "      <td>10:00 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ASIA CUP 2023\\n4 SEP 2023\\n10:00 AM IST</td>\n",
       "      <td>[2nd ODI , ]</td>\n",
       "      <td>[4 SEP 2023]</td>\n",
       "      <td>4 SEP 2023</td>\n",
       "      <td>10:00 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AUSTRALIA TOUR OF INDIA 2023-24\\n22 SEP 2023\\n...</td>\n",
       "      <td>[1st ODI , ]</td>\n",
       "      <td>[22 SEP 2023]</td>\n",
       "      <td>22 SEP 2023</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AUSTRALIA TOUR OF INDIA 2023-24\\n24 SEP 2023\\n...</td>\n",
       "      <td>[2nd ODI , ]</td>\n",
       "      <td>[24 SEP 2023]</td>\n",
       "      <td>24 SEP 2023</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AUSTRALIA TOUR OF INDIA 2023-24\\n27 SEP 2023\\n...</td>\n",
       "      <td>[3rd ODI , ]</td>\n",
       "      <td>[27 SEP 2023]</td>\n",
       "      <td>27 SEP 2023</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ICC MENS WORLD CUP 2023\\n8 OCT 2023\\n2:00 PM IST</td>\n",
       "      <td>[1st ODI , ]</td>\n",
       "      <td>[8 OCT 2023]</td>\n",
       "      <td>8 OCT 2023</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ICC MENS WORLD CUP 2023\\n11 OCT 2023\\n2:00 PM IST</td>\n",
       "      <td>[2nd ODI , ]</td>\n",
       "      <td>[11 OCT 2023]</td>\n",
       "      <td>11 OCT 2023</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ICC MENS WORLD CUP 2023\\n14 OCT 2023\\n2:00 PM IST</td>\n",
       "      <td>[3rd ODI , ]</td>\n",
       "      <td>[14 OCT 2023]</td>\n",
       "      <td>14 OCT 2023</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Match_title        Series  \\\n",
       "0            ASIA CUP 2023\\n2 SEP 2023\\n10:00 AM IST  [1st ODI , ]   \n",
       "1            ASIA CUP 2023\\n4 SEP 2023\\n10:00 AM IST  [2nd ODI , ]   \n",
       "2  AUSTRALIA TOUR OF INDIA 2023-24\\n22 SEP 2023\\n...  [1st ODI , ]   \n",
       "3  AUSTRALIA TOUR OF INDIA 2023-24\\n24 SEP 2023\\n...  [2nd ODI , ]   \n",
       "4  AUSTRALIA TOUR OF INDIA 2023-24\\n27 SEP 2023\\n...  [3rd ODI , ]   \n",
       "5   ICC MENS WORLD CUP 2023\\n8 OCT 2023\\n2:00 PM IST  [1st ODI , ]   \n",
       "6  ICC MENS WORLD CUP 2023\\n11 OCT 2023\\n2:00 PM IST  [2nd ODI , ]   \n",
       "7  ICC MENS WORLD CUP 2023\\n14 OCT 2023\\n2:00 PM IST  [3rd ODI , ]   \n",
       "\n",
       "           Place         Date          Time  \n",
       "0   [2 SEP 2023]   2 SEP 2023  10:00 AM IST  \n",
       "1   [4 SEP 2023]   4 SEP 2023  10:00 AM IST  \n",
       "2  [22 SEP 2023]  22 SEP 2023   1:30 PM IST  \n",
       "3  [24 SEP 2023]  24 SEP 2023   1:30 PM IST  \n",
       "4  [27 SEP 2023]  27 SEP 2023   1:30 PM IST  \n",
       "5   [8 OCT 2023]   8 OCT 2023   2:00 PM IST  \n",
       "6  [11 OCT 2023]  11 OCT 2023   2:00 PM IST  \n",
       "7  [14 OCT 2023]  14 OCT 2023   2:00 PM IST  "
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating Dataframe\n",
    "international_fixtures=pd.DataFrame({\"Match_title\":Match_title,\"Series\":Series,\"Place\":Place,\"Date\":Date,\"Time\":Time})\n",
    "international_fixtures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a817f4",
   "metadata": {},
   "source": [
    "3. Scrape the details of State-wise GDP of India from statisticstime.com. \n",
    "Url = http://statisticstimes.com/\n",
    "You have to find following details: A)\n",
    "Rank \n",
    "B) State \n",
    "C) GSDP(18-19)- at current prices \n",
    "D) GSDP(19-20)- at current prices \n",
    "E) Share(18-19) \n",
    "F) GDP($ billion) \n",
    "Note: - From statisticstimes home page you have to reach to economy page through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "9669f73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = selenium.webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "8523d414",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=(\"https://www.statisticstimes.com/\")\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "49465016",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.XPATH,'/html/body/div[1]/div/a').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "5d4034fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking on Economy button\n",
    "driver.find_element(By.XPATH,\"//div[@class='navbar']/div[2]/button\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "5047f6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking on India\n",
    "driver.find_element(By.XPATH,'/html/body/div[2]/div[1]/div[2]/div[2]/div/a[3]').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "9d17f072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clicking on GDP of Indian Economy\n",
    "GDP = driver.find_element(By.XPATH,'/html/body/div[2]/div[2]/div[3]/div').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "016337bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating empty list\n",
    "Rank = []\n",
    "State = []\n",
    "GSDP2 = []\n",
    "Share = []\n",
    "GDPbillion = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "45f3a609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Rank\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,\"//table[@class='display dataTable']/tbody/tr/td[1]\"):\n",
    "        Rank.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Rank.append(\"_\")\n",
    "    \n",
    "# Scraping State\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,\"//table[@class='display dataTable']/tbody/tr/td[2]\"):\n",
    "        State.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    State.append(\"_\")\n",
    "    \n",
    "# Scraping GSDP at current price (18-19)\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,\"//table[@class='display dataTable']/tbody/tr/td[4]\"):\n",
    "        GSDP2.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    GSDP2.append(\"_\")\n",
    "\n",
    "# Scraping Share (18-19)\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,\"//table[@class='display dataTable']/tbody/tr/td[5]\"):\n",
    "        Share.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Share.append(\"_\")\n",
    "    \n",
    "# Scraping GDP $ billion\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,\"//table[@class='display dataTable']/tbody/tr/td[6]\"):\n",
    "        GDPbillion.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    GDPbillion.append(\"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "61fb2835",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RANK</th>\n",
       "      <th>STATE</th>\n",
       "      <th>GSDP2</th>\n",
       "      <th>SHARE</th>\n",
       "      <th>GDPbillion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Primary Sector</td>\n",
       "      <td>19.37</td>\n",
       "      <td>18,973,486</td>\n",
       "      <td>17.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.1</td>\n",
       "      <td>Agriculture, forestry &amp; fishing</td>\n",
       "      <td>15.63</td>\n",
       "      <td>14,245,950</td>\n",
       "      <td>13.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.11</td>\n",
       "      <td>Crops</td>\n",
       "      <td>9.79</td>\n",
       "      <td>8,962,827</td>\n",
       "      <td>8.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.12</td>\n",
       "      <td>Livestock</td>\n",
       "      <td>3.35</td>\n",
       "      <td>2,862,908</td>\n",
       "      <td>2.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.13</td>\n",
       "      <td>Forestry &amp; logging</td>\n",
       "      <td>1.66</td>\n",
       "      <td>1,888,936</td>\n",
       "      <td>1.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.14</td>\n",
       "      <td>Fishing and aquaculture</td>\n",
       "      <td>0.83</td>\n",
       "      <td>531,280</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.2</td>\n",
       "      <td>Mining &amp; quarrying</td>\n",
       "      <td>3.74</td>\n",
       "      <td>4,727,536</td>\n",
       "      <td>4.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>Secondary Sector</td>\n",
       "      <td>44.49</td>\n",
       "      <td>50,584,861</td>\n",
       "      <td>46.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.1</td>\n",
       "      <td>Manufacturing</td>\n",
       "      <td>35.82</td>\n",
       "      <td>40,892,857</td>\n",
       "      <td>37.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.2</td>\n",
       "      <td>Electricity, gas, water supply &amp; other utility...</td>\n",
       "      <td>3.17</td>\n",
       "      <td>3,784,987</td>\n",
       "      <td>3.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.3</td>\n",
       "      <td>Construction</td>\n",
       "      <td>5.49</td>\n",
       "      <td>5,907,017</td>\n",
       "      <td>5.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>Tertairy Sector</td>\n",
       "      <td>36.14</td>\n",
       "      <td>39,549,816</td>\n",
       "      <td>36.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3.1</td>\n",
       "      <td>Trade, repair, hotels and restaurants</td>\n",
       "      <td>12.66</td>\n",
       "      <td>14,616,582</td>\n",
       "      <td>13.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3.11</td>\n",
       "      <td>Trade &amp; repair services</td>\n",
       "      <td>12.66</td>\n",
       "      <td>14,616,582</td>\n",
       "      <td>13.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3.2</td>\n",
       "      <td>Transport, storage, communication &amp; services r...</td>\n",
       "      <td>4.56</td>\n",
       "      <td>5,082,266</td>\n",
       "      <td>4.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3.21</td>\n",
       "      <td>Railways</td>\n",
       "      <td>0.44</td>\n",
       "      <td>415,391</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3.22</td>\n",
       "      <td>Services incidental to transport</td>\n",
       "      <td>2.70</td>\n",
       "      <td>3,281,339</td>\n",
       "      <td>3.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3.26</td>\n",
       "      <td>Storage</td>\n",
       "      <td>0.06</td>\n",
       "      <td>52,051</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3.27</td>\n",
       "      <td>Communication &amp; services related to broadcasting</td>\n",
       "      <td>1.37</td>\n",
       "      <td>1,333,485</td>\n",
       "      <td>1.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3.3</td>\n",
       "      <td>Financial services</td>\n",
       "      <td>5.36</td>\n",
       "      <td>6,273,832</td>\n",
       "      <td>5.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3.4</td>\n",
       "      <td>Real estate, ownership of dwelling &amp; professio...</td>\n",
       "      <td>5.94</td>\n",
       "      <td>5,926,791</td>\n",
       "      <td>5.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3.5</td>\n",
       "      <td>Public administration &amp; defence</td>\n",
       "      <td>3.51</td>\n",
       "      <td>3,617,774</td>\n",
       "      <td>3.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3.6</td>\n",
       "      <td>Other services</td>\n",
       "      <td>4.09</td>\n",
       "      <td>4,032,571</td>\n",
       "      <td>3.70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    RANK                                              STATE  GSDP2  \\\n",
       "0      1                                     Primary Sector  19.37   \n",
       "1    1.1                    Agriculture, forestry & fishing  15.63   \n",
       "2   1.11                                              Crops   9.79   \n",
       "3   1.12                                          Livestock   3.35   \n",
       "4   1.13                                 Forestry & logging   1.66   \n",
       "5   1.14                            Fishing and aquaculture   0.83   \n",
       "6    1.2                                 Mining & quarrying   3.74   \n",
       "7      2                                   Secondary Sector  44.49   \n",
       "8    2.1                                      Manufacturing  35.82   \n",
       "9    2.2  Electricity, gas, water supply & other utility...   3.17   \n",
       "10   2.3                                       Construction   5.49   \n",
       "11     3                                    Tertairy Sector  36.14   \n",
       "12   3.1              Trade, repair, hotels and restaurants  12.66   \n",
       "13  3.11                            Trade & repair services  12.66   \n",
       "14   3.2  Transport, storage, communication & services r...   4.56   \n",
       "15  3.21                                           Railways   0.44   \n",
       "16  3.22                   Services incidental to transport   2.70   \n",
       "17  3.26                                            Storage   0.06   \n",
       "18  3.27   Communication & services related to broadcasting   1.37   \n",
       "19   3.3                                 Financial services   5.36   \n",
       "20   3.4  Real estate, ownership of dwelling & professio...   5.94   \n",
       "21   3.5                    Public administration & defence   3.51   \n",
       "22   3.6                                     Other services   4.09   \n",
       "\n",
       "         SHARE GDPbillion  \n",
       "0   18,973,486      17.39  \n",
       "1   14,245,950      13.06  \n",
       "2    8,962,827       8.21  \n",
       "3    2,862,908       2.62  \n",
       "4    1,888,936       1.73  \n",
       "5      531,280       0.49  \n",
       "6    4,727,536       4.33  \n",
       "7   50,584,861      46.36  \n",
       "8   40,892,857      37.48  \n",
       "9    3,784,987       3.47  \n",
       "10   5,907,017       5.41  \n",
       "11  39,549,816      36.25  \n",
       "12  14,616,582      13.40  \n",
       "13  14,616,582      13.40  \n",
       "14   5,082,266       4.66  \n",
       "15     415,391       0.38  \n",
       "16   3,281,339       3.01  \n",
       "17      52,051       0.05  \n",
       "18   1,333,485       1.22  \n",
       "19   6,273,832       5.75  \n",
       "20   5,926,791       5.43  \n",
       "21   3,617,774       3.32  \n",
       "22   4,032,571       3.70  "
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INDIA=pd.DataFrame()\n",
    "INDIA['RANK']=Rank\n",
    "INDIA['STATE']=State\n",
    "INDIA['GSDP2']=GSDP2\n",
    "INDIA['SHARE']=Share\n",
    "INDIA['GDPbillion']=GDPbillion\n",
    "INDIA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f7658b",
   "metadata": {},
   "source": [
    "4. Scrape the details of trending repositories on Github.com. \n",
    "Url = https://github.com/\n",
    "You have to find the following details: \n",
    "A) Repository title \n",
    "B) Repository description \n",
    "C) Contributors count \n",
    "D) Language used \n",
    "Note: - From the home page you have to click on the trending option from Explore menu through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "eba4837a",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = selenium.webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "a1b1b10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=(\"https://github.com/\")\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "e6c3a297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click on explore\n",
    "explore = driver.find_element(By.XPATH,'/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/button')\n",
    "try:\n",
    "    explore.click()\n",
    "    trending = driver.find_element(By.XPATH,'/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/div/div[3]/ul/li[2]/a')\n",
    "    trending.click()\n",
    "except ElementNotInteractableException:\n",
    "    driver.get(trending.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "176a4828",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty list:\n",
    "URLs = []\n",
    "\n",
    "#Fetching urls for each repository\n",
    "repository = driver.find_elements(By.XPATH,'//h2[@class=\"h3 lh-condensed\"]/a')\n",
    "for i in repository:\n",
    "    URLs.append(i.get_attribute(\"href\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "64100cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "repository_title = []\n",
    "Description = []\n",
    "Contributors = []\n",
    "Language = []\n",
    "lang = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "3ef3e308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping data from all repository page\n",
    "for i in URLs:\n",
    "    driver.get(i)\n",
    "    \n",
    "    # Repository Titles\n",
    "    try:\n",
    "        title = driver.find_element(By.XPATH,'//strong[@class=\"mr-2 flex-self-stretch\"]')\n",
    "        repository_title.append(title.text)\n",
    "    except NoSuchElementException:\n",
    "        Description.append('-')\n",
    "    \n",
    "    # Description\n",
    "    \n",
    "    try:\n",
    "        desc = driver.find_element(By.XPATH,'//p[@class=\"f4 my-3\"]')\n",
    "        Description.append(desc.text)\n",
    "    except NoSuchElementException:\n",
    "        Description.append('-')\n",
    "    \n",
    "    # Contributor\n",
    "    \n",
    "    try:\n",
    "        contributor = driver.find_element(By.XPATH,'//div[@class=\"mt-3\"]')\n",
    "        Contributors.append(contributor.text.split(\"+\")[-1].strip())\n",
    "    except NoSuchElementException:\n",
    "        Contributors.append('-')\n",
    "    \n",
    "    # Languages \n",
    "    lang=[]\n",
    "    try:\n",
    "        for i in driver.find_elements(By.XPATH,'//span[@class=\"color-fg-default text-bold mr-1\"]'):\n",
    "            lang.append(i.text)\n",
    "        Language.append(lang)\n",
    "    except NoSuchElementException:\n",
    "        lang.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "af9c91e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Repository Title</th>\n",
       "      <th>Description</th>\n",
       "      <th>Contributors</th>\n",
       "      <th>Languages Used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>facechain</td>\n",
       "      <td>FaceChain is a deep-learning toolchain for gen...</td>\n",
       "      <td>-</td>\n",
       "      <td>[Python, Jupyter Notebook, Shell]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neuralangelo</td>\n",
       "      <td>Official implementation of \"Neuralangelo: High...</td>\n",
       "      <td>-</td>\n",
       "      <td>[Python, Shell, Jupyter Notebook]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wipeout-rewrite</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>[C, Other]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Python</td>\n",
       "      <td>All Algorithms implemented in Python</td>\n",
       "      <td>978 contributors</td>\n",
       "      <td>[Python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>infisical</td>\n",
       "      <td>♾ Infisical is an open-source, end-to-end encr...</td>\n",
       "      <td>85 releases</td>\n",
       "      <td>[TypeScript, Go, JavaScript, Shell, Makefile, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>roop</td>\n",
       "      <td>one-click deepfake (face swap)</td>\n",
       "      <td>5 releases</td>\n",
       "      <td>[Python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DoctorGPT</td>\n",
       "      <td>DoctorGPT is an LLM that can pass the US Medic...</td>\n",
       "      <td>-</td>\n",
       "      <td>[Jupyter Notebook]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>awesome-generative-ai</td>\n",
       "      <td>A curated list of modern Generative Artificial...</td>\n",
       "      <td>13 contributors</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>aws-devops-zero-to-hero</td>\n",
       "      <td>AWS zero to hero repo for devops engineers to ...</td>\n",
       "      <td>-</td>\n",
       "      <td>[Python, HCL, Shell, Dockerfile]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Conferences</td>\n",
       "      <td>Conference slides</td>\n",
       "      <td>-</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Fooocus</td>\n",
       "      <td>Focus on prompting and generating</td>\n",
       "      <td>-</td>\n",
       "      <td>[Python, Jupyter Notebook]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>awesome-scalability</td>\n",
       "      <td>The Patterns of Scalable, Reliable, and Perfor...</td>\n",
       "      <td>11 contributors</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Langchain-Chatchat</td>\n",
       "      <td>Langchain-Chatchat (formerly langchain-ChatGLM...</td>\n",
       "      <td>18 releases</td>\n",
       "      <td>[Python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Synapse_CoR</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>awesome-selfhosted</td>\n",
       "      <td>A list of Free Software network services and w...</td>\n",
       "      <td>1,243 contributors</td>\n",
       "      <td>[Makefile]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Auto_Simulated_Universe</td>\n",
       "      <td>崩坏：星穹铁道 模拟宇宙自动化 （Honkai Star Rail - Auto Simul...</td>\n",
       "      <td>12 releases</td>\n",
       "      <td>[Python, Batchfile]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>shiori</td>\n",
       "      <td>Simple bookmark manager built with Go</td>\n",
       "      <td>9 releases</td>\n",
       "      <td>[JavaScript, Go, Less, HTML, Makefile, Shell, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>stable-diffusion-webui</td>\n",
       "      <td>Stable Diffusion web UI</td>\n",
       "      <td>12 releases</td>\n",
       "      <td>[Python, JavaScript, HTML, CSS, Other]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>generative_agents</td>\n",
       "      <td>Generative Agents: Interactive Simulacra of Hu...</td>\n",
       "      <td>-</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>go-ethereum</td>\n",
       "      <td>Official Go implementation of the Ethereum pro...</td>\n",
       "      <td>174 releases</td>\n",
       "      <td>[Go, C, JavaScript, Assembly, Java, Sage, Other]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>CodeGeeX2</td>\n",
       "      <td>CodeGeeX2: A More Powerful Multilingual Code G...</td>\n",
       "      <td>-</td>\n",
       "      <td>[Python, Shell]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>hiring-without-whiteboards</td>\n",
       "      <td>⭐️ Companies that don't have a broken hiring p...</td>\n",
       "      <td>953 contributors</td>\n",
       "      <td>[JavaScript]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>localGPT</td>\n",
       "      <td>Chat with your documents on your local device ...</td>\n",
       "      <td>11 contributors</td>\n",
       "      <td>[Python, HTML, Dockerfile]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>build-your-own-x</td>\n",
       "      <td>Master programming by recreating your favorite...</td>\n",
       "      <td>96 contributors</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>New-Grad-2024</td>\n",
       "      <td>👋 Hey there new grad🎉! We've put together a co...</td>\n",
       "      <td>41 contributors</td>\n",
       "      <td>[Python]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Repository Title  \\\n",
       "0                    facechain   \n",
       "1                 neuralangelo   \n",
       "2              wipeout-rewrite   \n",
       "3                       Python   \n",
       "4                    infisical   \n",
       "5                         roop   \n",
       "6                    DoctorGPT   \n",
       "7        awesome-generative-ai   \n",
       "8      aws-devops-zero-to-hero   \n",
       "9                  Conferences   \n",
       "10                     Fooocus   \n",
       "11         awesome-scalability   \n",
       "12          Langchain-Chatchat   \n",
       "13                 Synapse_CoR   \n",
       "14          awesome-selfhosted   \n",
       "15     Auto_Simulated_Universe   \n",
       "16                      shiori   \n",
       "17      stable-diffusion-webui   \n",
       "18           generative_agents   \n",
       "19                 go-ethereum   \n",
       "20                   CodeGeeX2   \n",
       "21  hiring-without-whiteboards   \n",
       "22                    localGPT   \n",
       "23            build-your-own-x   \n",
       "24               New-Grad-2024   \n",
       "\n",
       "                                          Description        Contributors  \\\n",
       "0   FaceChain is a deep-learning toolchain for gen...                   -   \n",
       "1   Official implementation of \"Neuralangelo: High...                   -   \n",
       "2                                                   -                   -   \n",
       "3                All Algorithms implemented in Python    978 contributors   \n",
       "4   ♾ Infisical is an open-source, end-to-end encr...         85 releases   \n",
       "5                      one-click deepfake (face swap)          5 releases   \n",
       "6   DoctorGPT is an LLM that can pass the US Medic...                   -   \n",
       "7   A curated list of modern Generative Artificial...     13 contributors   \n",
       "8   AWS zero to hero repo for devops engineers to ...                   -   \n",
       "9                                   Conference slides                   -   \n",
       "10                  Focus on prompting and generating                   -   \n",
       "11  The Patterns of Scalable, Reliable, and Perfor...     11 contributors   \n",
       "12  Langchain-Chatchat (formerly langchain-ChatGLM...         18 releases   \n",
       "13                                                  -                   -   \n",
       "14  A list of Free Software network services and w...  1,243 contributors   \n",
       "15  崩坏：星穹铁道 模拟宇宙自动化 （Honkai Star Rail - Auto Simul...         12 releases   \n",
       "16              Simple bookmark manager built with Go          9 releases   \n",
       "17                            Stable Diffusion web UI         12 releases   \n",
       "18  Generative Agents: Interactive Simulacra of Hu...                   -   \n",
       "19  Official Go implementation of the Ethereum pro...        174 releases   \n",
       "20  CodeGeeX2: A More Powerful Multilingual Code G...                   -   \n",
       "21  ⭐️ Companies that don't have a broken hiring p...    953 contributors   \n",
       "22  Chat with your documents on your local device ...     11 contributors   \n",
       "23  Master programming by recreating your favorite...     96 contributors   \n",
       "24  👋 Hey there new grad🎉! We've put together a co...     41 contributors   \n",
       "\n",
       "                                       Languages Used  \n",
       "0                   [Python, Jupyter Notebook, Shell]  \n",
       "1                   [Python, Shell, Jupyter Notebook]  \n",
       "2                                          [C, Other]  \n",
       "3                                            [Python]  \n",
       "4   [TypeScript, Go, JavaScript, Shell, Makefile, ...  \n",
       "5                                            [Python]  \n",
       "6                                  [Jupyter Notebook]  \n",
       "7                                                  []  \n",
       "8                    [Python, HCL, Shell, Dockerfile]  \n",
       "9                                                  []  \n",
       "10                         [Python, Jupyter Notebook]  \n",
       "11                                                 []  \n",
       "12                                           [Python]  \n",
       "13                                                 []  \n",
       "14                                         [Makefile]  \n",
       "15                                [Python, Batchfile]  \n",
       "16  [JavaScript, Go, Less, HTML, Makefile, Shell, ...  \n",
       "17             [Python, JavaScript, HTML, CSS, Other]  \n",
       "18                                                 []  \n",
       "19   [Go, C, JavaScript, Assembly, Java, Sage, Other]  \n",
       "20                                    [Python, Shell]  \n",
       "21                                       [JavaScript]  \n",
       "22                         [Python, HTML, Dockerfile]  \n",
       "23                                                 []  \n",
       "24                                           [Python]  "
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "github = pd.DataFrame({\"Repository Title\":repository_title,\"Description\": Description,\"Contributors\": Contributors,\"Languages Used\":Language})\n",
    "github"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9c7863",
   "metadata": {},
   "source": [
    "5. Scrape the details of top 100 songs on billiboard.com. Url = https:/www.billboard.com/\n",
    "You have to find the following details: \n",
    "A) Song name \n",
    "B) Artist name \n",
    "C) Last week rank \n",
    "D) Peak rank \n",
    "E) Weeks on board \n",
    "Note: - From the home page you have to click on the charts option then hot 100-page link through code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "fa27dc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = selenium.webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "95679a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=(\"https://www.billboard.com/\")\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "1c7071f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking on charts\n",
    "charts=driver.find_element(By.XPATH,'/html/body/div[3]/header/div/div[2]/div/div/div[2]/div[2]/div/div/nav/ul/li[1]/a').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "a12a043d",
   "metadata": {},
   "outputs": [],
   "source": [
    "view_chart = driver.find_element(By.XPATH,'/html/body/div[3]/main/div[2]/div[1]/div[1]/div/div/div[3]/a').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "b67477f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating empty lists\n",
    "Song_Name = []\n",
    "Artist_Name = []\n",
    "Last_week_rank = []\n",
    "Peak_rank = []\n",
    "Weeks_on_board = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "206d26bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping name\n",
    "for i in driver.find_elements(By.XPATH,'//li[@class=\"lrv-u-width-100p\"]'):\n",
    "    Song_Name.append(i.text)\n",
    "len(Song_Name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "6d962110",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scrappin Artist name 1 st one\n",
    "Artist_Name.append(driver.find_element(By.XPATH,\"//span[@class='c-label  a-no-trucate a-font-primary-s lrv-u-font-size-14@mobile-max u-line-height-normal@mobile-max u-letter-spacing-0021 lrv-u-display-block a-truncate-ellipsis-2line u-max-width-330 u-max-width-230@tablet-only u-font-size-20@tablet']\").text)\n",
    "#Remainig Artist Name\n",
    "artistTag=driver.find_elements(By.XPATH,\"//span[@class='c-label  a-no-trucate a-font-primary-s lrv-u-font-size-14@mobile-max u-line-height-normal@mobile-max u-letter-spacing-0021 lrv-u-display-block a-truncate-ellipsis-2line u-max-width-330 u-max-width-230@tablet-only']\")\n",
    "Artist_Name.extend([i.text for i in artistTag])\n",
    "#Scapping Rank\n",
    "rank=[]\n",
    "rankTag=driver.find_elements(By.XPATH,\"//span[@class='c-label  a-font-primary-bold-l a-font-primary-m@mobile-max u-font-weight-normal@mobile-max lrv-u-padding-tb-050@mobile-max u-font-size-32@tablet']\")\n",
    "rank.extend([i.text for i in rankTag[:3]])\n",
    "#Remaining RAnk\n",
    "Rank=[]\n",
    "RankTag=driver.find_elements(By.XPATH,\"//span[@class='c-label  a-font-primary-m lrv-u-padding-tb-050@mobile-max']\")\n",
    "Rank.extend([i.text for i in RankTag])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "6d5b13da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing ''\n",
    "for i in Rank:\n",
    "    if i=='':\n",
    "        Rank.remove(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "5a36aba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slicing as per requirement\n",
    "lastweekpos=Rank[0::3]\n",
    "lastweekpos.insert(0,rank[0])\n",
    "peakPos=Rank[1::3]\n",
    "peakPos.insert(0,rank[1])\n",
    "weeksonBoard=Rank[2::3]\n",
    "weeksonBoard.insert(0,rank[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "1442663c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SongName</th>\n",
       "      <th>ArtistName</th>\n",
       "      <th>Last Week</th>\n",
       "      <th>PeekPosition</th>\n",
       "      <th>Weeks On board</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Last Night\\nMorgan Wallen\\n1\\n1\\n28</td>\n",
       "      <td>Morgan Wallen</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fast Car\\nLuke Combs\\n2\\n2\\n20</td>\n",
       "      <td>Luke Combs</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cruel Summer\\nTaylor Swift\\n4\\n3\\n14</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Calm Down\\nRema &amp; Selena Gomez\\n6\\n3\\n49</td>\n",
       "      <td>Rema &amp; Selena Gomez</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fukumean\\nGunna\\n7\\n4\\n8</td>\n",
       "      <td>Gunna</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Lagunas\\nPeso Pluma &amp; Jasiel Nunez\\n-\\n77\\n6</td>\n",
       "      <td>Peso Pluma &amp; Jasiel Nunez</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Overdrive\\nPost Malone\\n68\\n47\\n3</td>\n",
       "      <td>Post Malone</td>\n",
       "      <td>-</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Bzrp Music Sessions, Vol. 55\\nBizarrap &amp; Peso ...</td>\n",
       "      <td>Bizarrap &amp; Peso Pluma</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Dawns\\nZach Bryan Featuring Maggie Rogers\\n-\\n...</td>\n",
       "      <td>Zach Bryan Featuring Maggie Rogers</td>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Rubicon\\nPeso Pluma\\n-\\n63\\n6</td>\n",
       "      <td>Peso Pluma</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             SongName  \\\n",
       "0                 Last Night\\nMorgan Wallen\\n1\\n1\\n28   \n",
       "1                      Fast Car\\nLuke Combs\\n2\\n2\\n20   \n",
       "2                Cruel Summer\\nTaylor Swift\\n4\\n3\\n14   \n",
       "3            Calm Down\\nRema & Selena Gomez\\n6\\n3\\n49   \n",
       "4                            Fukumean\\nGunna\\n7\\n4\\n8   \n",
       "..                                                ...   \n",
       "95       Lagunas\\nPeso Pluma & Jasiel Nunez\\n-\\n77\\n6   \n",
       "96                  Overdrive\\nPost Malone\\n68\\n47\\n3   \n",
       "97  Bzrp Music Sessions, Vol. 55\\nBizarrap & Peso ...   \n",
       "98  Dawns\\nZach Bryan Featuring Maggie Rogers\\n-\\n...   \n",
       "99                      Rubicon\\nPeso Pluma\\n-\\n63\\n6   \n",
       "\n",
       "                            ArtistName Last Week PeekPosition Weeks On board  \n",
       "0                        Morgan Wallen                                        \n",
       "1                           Luke Combs         2            2             20  \n",
       "2                         Taylor Swift         4            3             14  \n",
       "3                  Rema & Selena Gomez         6            3             49  \n",
       "4                                Gunna         7            4              8  \n",
       "..                                 ...       ...          ...            ...  \n",
       "95           Peso Pluma & Jasiel Nunez                                        \n",
       "96                         Post Malone         -           82              1  \n",
       "97               Bizarrap & Peso Pluma                                        \n",
       "98  Zach Bryan Featuring Maggie Rogers        55           55              2  \n",
       "99                          Peso Pluma                                        \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Dataframe\n",
    "df=pd.DataFrame()\n",
    "df['SongName']=Song_Name[0:100]\n",
    "df['ArtistName']=Artist_Name\n",
    "df['Last Week']=lastweekpos[0:100]\n",
    "df[\"PeekPosition\"]=peakPos[0:100]\n",
    "df['Weeks On board']=weeksonBoard[0:100]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "1cf96e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d0b0c4",
   "metadata": {},
   "source": [
    "6. Scrape the details of Highest selling novels. \n",
    "compare \n",
    "A) Book name \n",
    "B) Author name \n",
    "C) Volumes sold \n",
    "D) Publisher \n",
    "E) Genre\n",
    "Url = https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey\u0002You have to find the following details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "7849fd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = selenium.webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "8770b1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get webpage\n",
    "driver.get(\"https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "f7dca9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty list\n",
    "Bookname = []\n",
    "Authorname = []\n",
    "Volumessold = []\n",
    "Publisher = []\n",
    "Genre = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "77afb543",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping book names data\n",
    "for i in driver.find_elements(By.XPATH,\"//tbody//tr/td[2]\"):\n",
    "    Bookname.append(i.text)\n",
    "    \n",
    "#Scraping author names data\n",
    "for i in driver.find_elements(By.XPATH,\"//tbody/tr/td[3]\"):\n",
    "    try:\n",
    "        if i.text == '0' : raise NoSuchElementException\n",
    "        Authorname.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Authorname.append('-')\n",
    "\n",
    "#Scraping data of volumes sold\n",
    "for i in driver.find_elements(By.XPATH,\"//tbody/tr/td[4]\"):\n",
    "    Volumessold.append(i.text)\n",
    "    \n",
    "#Scraping data of publisher names\n",
    "for i in driver.find_elements(By.XPATH,\"//tbody/tr/td[5]\"):\n",
    "    Publisher.append(i.text)\n",
    "    \n",
    "#Scraping data of genre\n",
    "for i in driver.find_elements(By.XPATH,\"//tbody/tr/td[6]\"):\n",
    "    Genre.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "0c5af51f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book Name</th>\n",
       "      <th>Author</th>\n",
       "      <th>Volume sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Book Name            Author  \\\n",
       "0                                   Da Vinci Code,The        Brown, Dan   \n",
       "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4                                Fifty Shades of Grey      James, E. L.   \n",
       "..                                                ...               ...   \n",
       "95                                          Ghost,The    Harris, Robert   \n",
       "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "   Volume sold        Publisher                        Genre  \n",
       "0    5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "1    4,475,152       Bloomsbury           Children's Fiction  \n",
       "2    4,200,654       Bloomsbury           Children's Fiction  \n",
       "3    4,179,479       Bloomsbury           Children's Fiction  \n",
       "4    3,758,936     Random House              Romance & Sagas  \n",
       "..         ...              ...                          ...  \n",
       "95     807,311     Random House   General & Literary Fiction  \n",
       "96     794,201          Penguin        Food & Drink: General  \n",
       "97     792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "98     791,507            Orion           Biography: General  \n",
       "99     791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating dataframe for scraped data\n",
    "Novels=pd.DataFrame({})\n",
    "Novels['Book Name'] = Bookname\n",
    "Novels['Author'] = Authorname\n",
    "Novels['Volume sold'] = Volumessold\n",
    "Novels['Publisher'] = Publisher\n",
    "Novels['Genre'] = Genre\n",
    "Novels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "05416337",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88a931a",
   "metadata": {},
   "source": [
    "7. Scrape the details most watched tv series of all time from imdb.com. \n",
    "Url = https://www.imdb.com/list/ls095964455/ You \n",
    "have to find the following details: \n",
    "A) Name \n",
    "B) Year span \n",
    "C) Genre \n",
    "D) Run time \n",
    "E) Ratings \n",
    "F) Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "d1358f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = selenium.webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "a9098d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get webpage\n",
    "driver.get(\"https://www.imdb.com/list/ls095964455/\")\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "00d36206",
   "metadata": {},
   "outputs": [],
   "source": [
    "Name = []\n",
    "Year_span = []\n",
    "Genre = []\n",
    "Run_time = []\n",
    "Ratings = []\n",
    "Votes = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "089fda50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping data of Names\n",
    "for i in driver.find_elements(By.XPATH,\"//h3[@class='lister-item-header']/a\"):\n",
    "    Name.append(i.text)\n",
    "    \n",
    "#Scraping data of Year span\n",
    "for i in driver.find_elements(By.XPATH,\"//span[@class='lister-item-year text-muted unbold']\"):\n",
    "    Year_span.append(i.text)\n",
    "    \n",
    "#Scraping data of Run time\n",
    "for i in driver.find_elements(By.XPATH,\"//span[@class='runtime']\"):\n",
    "    Run_time.append(i.text)\n",
    "    \n",
    "#Scraping data of Ratings\n",
    "for i in driver.find_elements(By.XPATH,\"//div[@class='ipl-rating-star small']//span[2]\"):\n",
    "    Ratings.append(i.text)\n",
    "    \n",
    "#Scraping data of genre\n",
    "for i in driver.find_elements(By.XPATH,\"//span[@class='genre']\"):\n",
    "    Genre.append(i.text)\n",
    "    \n",
    "#Scraping data of votes\n",
    "for i in driver.find_elements(By.XPATH,\"//div[@class='lister-item-content']//p[4]/span[2]\"):\n",
    "    Votes.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "45097479",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year Span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Run Time</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "      <td>9.2</td>\n",
       "      <td>2,192,705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016–2024)</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1,266,517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010–2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>1,040,804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>305,916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014–2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>264,992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Reign</td>\n",
       "      <td>(2013–2017)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>52,417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Series of Unfortunate Events</td>\n",
       "      <td>(2017–2019)</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>50 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>64,444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Criminal Minds</td>\n",
       "      <td>(2005– )</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>210,073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Scream: The TV Series</td>\n",
       "      <td>(2015–2019)</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7</td>\n",
       "      <td>43,676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Haunting of Hill House</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>572 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>263,598</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Name    Year Span                     Genre  \\\n",
       "0                  Game of Thrones  (2011–2019)  Action, Adventure, Drama   \n",
       "1                  Stranger Things  (2016–2024)    Drama, Fantasy, Horror   \n",
       "2                 The Walking Dead  (2010–2022)   Drama, Horror, Thriller   \n",
       "3                   13 Reasons Why  (2017–2020)  Drama, Mystery, Thriller   \n",
       "4                          The 100  (2014–2020)    Drama, Mystery, Sci-Fi   \n",
       "..                             ...          ...                       ...   \n",
       "95                           Reign  (2013–2017)                     Drama   \n",
       "96  A Series of Unfortunate Events  (2017–2019)  Adventure, Comedy, Drama   \n",
       "97                  Criminal Minds     (2005– )     Crime, Drama, Mystery   \n",
       "98           Scream: The TV Series  (2015–2019)      Comedy, Crime, Drama   \n",
       "99      The Haunting of Hill House       (2018)    Drama, Horror, Mystery   \n",
       "\n",
       "   Run Time Ratings      Votes  \n",
       "0    57 min     9.2  2,192,705  \n",
       "1    51 min     8.7  1,266,517  \n",
       "2    44 min     8.1  1,040,804  \n",
       "3    60 min     7.5    305,916  \n",
       "4    43 min     7.6    264,992  \n",
       "..      ...     ...        ...  \n",
       "95   42 min     7.5     52,417  \n",
       "96   50 min     7.8     64,444  \n",
       "97   42 min     8.1    210,073  \n",
       "98   45 min       7     43,676  \n",
       "99  572 min     8.6    263,598  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating dataframe for scraped data\n",
    "TVseries=pd.DataFrame({})\n",
    "TVseries['Name'] = Name\n",
    "TVseries['Year Span'] = Year_span\n",
    "TVseries['Genre'] = Genre\n",
    "TVseries['Run Time'] = Run_time\n",
    "TVseries['Ratings'] = Ratings\n",
    "TVseries['Votes'] = Votes\n",
    "TVseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "bb454b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ad7a53",
   "metadata": {},
   "source": [
    "8. Details of Datasets from UCI machine learning repositories. \n",
    "Url = https://archive.ics.uci.edu/\n",
    "You have to find the following details: \n",
    "A) Dataset name \n",
    "B) Data type \n",
    "C) Task \n",
    "D) Attribute type \n",
    "E) No of instances \n",
    "F) No of attribute G) Year \n",
    "Note: - from the home page you have to go to the Show All Dataset page through code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7927d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = selenium.webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b53c11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get webpage\n",
    "driver.get(\" https://archive.ics.uci.edu/\")\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc01d94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accept button\n",
    "accept_button=driver.find_element(By.XPATH,'//button[@class=\"btn-primary btn-sm btn m-1\"]')\n",
    "accept_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f1d0520",
   "metadata": {},
   "outputs": [],
   "source": [
    "# click on datasets\n",
    "datasets=driver.find_element(By.XPATH,'/html/body/div/div[1]/div[1]/header/nav/ul/li[1]/a')\n",
    "datasets.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6045a6cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n",
      "400\n",
      "410\n",
      "420\n",
      "430\n",
      "440\n",
      "450\n",
      "460\n",
      "470\n",
      "480\n",
      "490\n",
      "500\n",
      "510\n",
      "520\n",
      "530\n",
      "540\n",
      "550\n",
      "560\n",
      "570\n",
      "580\n",
      "590\n",
      "600\n",
      "610\n",
      "620\n"
     ]
    }
   ],
   "source": [
    "# Getting URL of each dataset\n",
    "url=[]\n",
    "for i in range(63):\n",
    "    urls=driver.find_elements(By.XPATH,'//div[@class=\"relative col-span-8 sm:col-span-7\"]/h2/a')\n",
    "    for u in urls:\n",
    "        url.append(u.get_attribute(\"href\"))\n",
    "        \n",
    "    #click on next button\n",
    "    if len(url)<=620:\n",
    "        next_button=driver.find_element(By.XPATH,'//div[@class=\"btn-group\"]/button[2]')\n",
    "        next_button.click()\n",
    "        print(len(url))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e833a94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty list:\n",
    "name=[]\n",
    "data_type=[]\n",
    "task=[]\n",
    "attribute_type=[]\n",
    "no_of_instance=[]\n",
    "year=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "296df50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate each url and get necessary data\n",
    "for u in url:\n",
    "    driver.get(u)\n",
    "\n",
    "    # Dataset Name\n",
    "    try:\n",
    "        nm=driver.find_element(By.XPATH,'//h1[@class=\"text-3xl font-semibold text-primary-content\"]')\n",
    "        name.append(nm.text)\n",
    "    except NoSuchElementException:\n",
    "        name.append(None)\n",
    "    \n",
    "    # Data type\n",
    "    try:\n",
    "        d_type=driver.find_element(By.XPATH,'//div[@class=\"grid grid-cols-8 gap-4 md:grid-cols-12\"]/div[1]/p')\n",
    "        data_type.append(d_type.text)\n",
    "    except NoSuchElementException:\n",
    "        data_type.append(None)\n",
    "    \n",
    "    # Associated Tasks \n",
    "    try:\n",
    "        tsk=driver.find_element(By.XPATH,'//div[@class=\"grid grid-cols-8 gap-4 md:grid-cols-12\"]/div[3]/p')\n",
    "        task.append(tsk.text)\n",
    "    except NoSuchElementException:\n",
    "        task.append(None)\n",
    "    \n",
    "    # Attribute Type\n",
    "    try:\n",
    "        attribute=driver.find_element(By.XPATH,'//div[@class=\"grid grid-cols-8 gap-4 md:grid-cols-12\"]/div[4]/p')\n",
    "        attribute_type.append(attribute.text)\n",
    "    except NoSuchElementException:\n",
    "        attribute_type.append(None)\n",
    "    \n",
    "    # No of Instances\n",
    "    try:\n",
    "        instance=driver.find_element(By.XPATH,'//div[@class=\"grid grid-cols-8 gap-4 md:grid-cols-12\"]/div[5]/p')\n",
    "        no_of_instance.append(instance.text)\n",
    "    except NoSuchElementException:\n",
    "        no_of_instance.append(None)\n",
    "    \n",
    "    # Year\n",
    "    try:\n",
    "        yr=driver.find_element(By.XPATH,'//h2[@class=\"text-primary-content\"]')\n",
    "        year.append(yr.text.split(\"/\")[-1])\n",
    "    except NoSuchElementException:\n",
    "        year.append(None)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b8126ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quit the Driver\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92d9050f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset Name</th>\n",
       "      <th>Data Type</th>\n",
       "      <th>Associated Tasks</th>\n",
       "      <th>Attribute Type</th>\n",
       "      <th>No of Instances</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Iris</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>150</td>\n",
       "      <td>1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Heart Disease</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>303</td>\n",
       "      <td>1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>48842</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dry Bean Dataset</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>13611</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Diabetes</td>\n",
       "      <td>Multivariate, Time-Series</td>\n",
       "      <td>-</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>-</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>DBWorld e-mails</td>\n",
       "      <td>Text</td>\n",
       "      <td>Classification</td>\n",
       "      <td>-</td>\n",
       "      <td>64</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>Firm-Teacher_Clave-Direction_Classification</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>-</td>\n",
       "      <td>10800</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>Discrete Tone Image Dataset</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>-</td>\n",
       "      <td>71</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>extention of Z-Alizadeh sani dataset</td>\n",
       "      <td>-</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>303</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>Shoulder Implant X-Ray Manufacturer Classifica...</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>597</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>630 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Dataset Name  \\\n",
       "0                                                 Iris   \n",
       "1                                        Heart Disease   \n",
       "2                                                Adult   \n",
       "3                                     Dry Bean Dataset   \n",
       "4                                             Diabetes   \n",
       "..                                                 ...   \n",
       "625                                    DBWorld e-mails   \n",
       "626        Firm-Teacher_Clave-Direction_Classification   \n",
       "627                        Discrete Tone Image Dataset   \n",
       "628               extention of Z-Alizadeh sani dataset   \n",
       "629  Shoulder Implant X-Ray Manufacturer Classifica...   \n",
       "\n",
       "                     Data Type Associated Tasks              Attribute Type  \\\n",
       "0                 Multivariate   Classification                        Real   \n",
       "1                 Multivariate   Classification  Categorical, Integer, Real   \n",
       "2                 Multivariate   Classification        Categorical, Integer   \n",
       "3                 Multivariate   Classification               Integer, Real   \n",
       "4    Multivariate, Time-Series                -        Categorical, Integer   \n",
       "..                         ...              ...                         ...   \n",
       "625                       Text   Classification                           -   \n",
       "626               Multivariate   Classification                           -   \n",
       "627               Multivariate   Classification                           -   \n",
       "628                          -   Classification               Integer, Real   \n",
       "629               Multivariate   Classification                        Real   \n",
       "\n",
       "    No of Instances  Year  \n",
       "0               150  1988  \n",
       "1               303  1988  \n",
       "2             48842  1996  \n",
       "3             13611  2020  \n",
       "4                 -  None  \n",
       "..              ...   ...  \n",
       "625              64  2011  \n",
       "626           10800  2015  \n",
       "627              71  2018  \n",
       "628             303  2017  \n",
       "629             597  2020  \n",
       "\n",
       "[630 rows x 6 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating DataFrame        \n",
    "df_dataset=pd.DataFrame({\"Dataset Name\":name,\"Data Type\":data_type,\"Associated Tasks\":task,\"Attribute Type\":attribute_type,\n",
    "                         \"No of Instances\":no_of_instance,\"Year\": year})\n",
    "df_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e35086",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
